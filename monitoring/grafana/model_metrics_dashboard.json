{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 0,
  "id": null,
  "title": "Model Performance Dashboard",
  "description": "Dashboard for monitoring emotion detection model performance metrics",
  "tags": ["model", "performance", "multilingual"],
  "time": {
    "from": "now-6h",
    "to": "now"
  },
  "timepicker": {
    "refresh_intervals": [
      "5s",
      "10s",
      "30s",
      "1m",
      "5m",
      "15m",
      "30m",
      "1h",
      "2h",
      "1d"
    ],
    "time_options": [
      "5m",
      "15m",
      "1h",
      "6h",
      "12h",
      "24h",
      "2d",
      "7d",
      "30d"
    ]
  },
  "panels": [
    {
      "title": "Model Inference Time",
      "type": "graph",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(model_inference_time_seconds_bucket[5m])) by (le))",
          "legendFormat": "95th Percentile",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.50, sum(rate(model_inference_time_seconds_bucket[5m])) by (le))",
          "legendFormat": "Median",
          "refId": "B"
        },
        {
          "expr": "sum(rate(model_inference_time_seconds_sum[5m])) / sum(rate(model_inference_time_seconds_count[5m]))",
          "legendFormat": "Average",
          "refId": "C"
        }
      ],
      "datasource": "Prometheus",
      "renderer": "flot",
      "yaxes": [
        {
          "label": "seconds",
          "show": true,
          "logBase": 1,
          "min": "0"
        },
        {
          "show": false
        }
      ],
      "xaxis": {
        "show": true
      },
      "dashLength": 10,
      "linewidth": 1,
      "pointradius": 2,
      "bars": false,
      "lines": true,
      "fill": 1,
      "fillGradient": 0,
      "aliasColors": {},
      "seriesOverrides": [],
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "description": "Time taken for model inference across different percentiles"
    },
    {
      "title": "Model Errors",
      "type": "graph",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "id": 2,
      "targets": [
        {
          "expr": "sum(rate(model_errors_total[5m]))",
          "legendFormat": "Error Rate",
          "refId": "A"
        },
        {
          "expr": "sum(rate(model_errors_total[5m])) / sum(rate(model_requests_total[5m]))",
          "legendFormat": "Error Ratio",
          "refId": "B"
        }
      ],
      "datasource": "Prometheus",
      "renderer": "flot",
      "yaxes": [
        {
          "label": "count",
          "show": true,
          "logBase": 1,
          "min": "0"
        },
        {
          "show": false
        }
      ],
      "xaxis": {
        "show": true
      },
      "dashLength": 10,
      "linewidth": 1,
      "pointradius": 2,
      "bars": false,
      "lines": true,
      "fill": 1,
      "fillGradient": 0,
      "aliasColors": {},
      "seriesOverrides": [],
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "description": "Rate of model prediction errors"
    },
    {
      "title": "Memory Usage",
      "type": "gauge",
      "gridPos": {
        "h": 8,
        "w": 6,
        "x": 0,
        "y": 8
      },
      "id": 3,
      "targets": [
        {
          "expr": "model_memory_usage_bytes{instance=\"localhost:8000\"} / 1024 / 1024",
          "refId": "A"
        }
      ],
      "datasource": "Prometheus",
      "options": {
        "fieldOptions": {
          "calcs": ["last"],
          "defaults": {
            "mappings": [],
            "max": 1024,
            "min": 0,
            "thresholds": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 512
              },
              {
                "color": "red",
                "value": 768
              }
            ],
            "unit": "megabytes"
          },
          "override": {},
          "values": false
        },
        "orientation": "auto",
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "description": "Current memory usage of the model"
    },
    {
      "title": "Model Load Time",
      "type": "stat",
      "gridPos": {
        "h": 8,
        "w": 6,
        "x": 6,
        "y": 8
      },
      "id": 4,
      "targets": [
        {
          "expr": "model_load_time_seconds",
          "refId": "A"
        }
      ],
      "datasource": "Prometheus",
      "options": {
        "fieldOptions": {
          "calcs": ["last"],
          "defaults": {
            "mappings": [],
            "thresholds": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "yellow",
                "value": 3
              },
              {
                "color": "red",
                "value": 5
              }
            ],
            "unit": "s"
          },
          "override": {},
          "values": false
        },
        "orientation": "auto",
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "displayMode": "basic"
      },
      "description": "Time taken to load the model"
    },
    {
      "title": "Batch Size Distribution",
      "type": "graph",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 8
      },
      "id": 5,
      "targets": [
        {
          "expr": "sum(rate(batch_size_distribution_bucket[5m])) by (le)",
          "legendFormat": "{{le}}",
          "refId": "A"
        }
      ],
      "datasource": "Prometheus",
      "renderer": "flot",
      "yaxes": [
        {
          "label": "count",
          "show": true,
          "logBase": 1,
          "min": "0"
        },
        {
          "show": false
        }
      ],
      "xaxis": {
        "show": true
      },
      "dashLength": 10,
      "linewidth": 1,
      "pointradius": 2,
      "bars": true,
      "lines": false,
      "fill": 1,
      "fillGradient": 0,
      "aliasColors": {},
      "seriesOverrides": [],
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "description": "Distribution of batch sizes processed by the model"
    },
    {
      "title": "Language Distribution",
      "type": "pie",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 16
      },
      "id": 6,
      "targets": [
        {
          "expr": "sum(rate(detected_language_total[5m])) by (language)",
          "legendFormat": "{{language}}",
          "refId": "A"
        }
      ],
      "datasource": "Prometheus",
      "options": {
        "legend": {
          "show": true,
          "values": true,
          "percentage": true
        },
        "pieType": "pie",
        "strokeWidth": 1,
        "displayLabels": ["name", "value"],
        "tooltipOptions": {
          "mode": "single"
        }
      },
      "description": "Distribution of detected languages in processed texts"
    },
    {
      "title": "Cache Performance",
      "type": "graph",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 16
      },
      "id": 7,
      "targets": [
        {
          "expr": "sum(rate(cache_hits_total[5m]))",
          "legendFormat": "Hits",
          "refId": "A"
        },
        {
          "expr": "sum(rate(cache_misses_total[5m]))",
          "legendFormat": "Misses",
          "refId": "B"
        },
        {
          "expr": "sum(rate(cache_hits_total[5m])) / (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))",
          "legendFormat": "Hit Ratio",
          "refId": "C"
        }
      ],
      "datasource": "Prometheus",
      "renderer": "flot",
      "yaxes": [
        {
          "label": "count",
          "show": true,
          "logBase": 1,
          "min": "0"
        },
        {
          "show": false
        }
      ],
      "xaxis": {
        "show": true
      },
      "dashLength": 10,
      "linewidth": 1,
      "pointradius": 2,
      "bars": false,
      "lines": true,
      "fill": 1,
      "fillGradient": 0,
      "aliasColors": {},
      "seriesOverrides": [],
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "description": "Cache hit/miss performance metrics"
    },
    {
      "title": "Emotion Distribution",
      "type": "bar",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 24
      },
      "id": 8,
      "targets": [
        {
          "expr": "sum(rate(emotion_prediction_total[5m])) by (emotion)",
          "legendFormat": "{{emotion}}",
          "refId": "A"
        }
      ],
      "datasource": "Prometheus",
      "options": {
        "showLabels": true,
        "showValues": true
      },
      "description": "Distribution of predicted emotions"
    },
    {
      "title": "Model Prediction Confidence",
      "type": "graph",
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 24
      },
      "id": 9,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(prediction_confidence_bucket[5m])) by (le))",
          "legendFormat": "95th Percentile",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.50, sum(rate(prediction_confidence_bucket[5m])) by (le))",
          "legendFormat": "Median",
          "refId": "B"
        },
        {
          "expr": "sum(rate(prediction_confidence_sum[5m])) / sum(rate(prediction_confidence_count[5m]))",
          "legendFormat": "Average",
          "refId": "C"
        }
      ],
      "datasource": "Prometheus",
      "renderer": "flot",
      "yaxes": [
        {
          "label": "confidence",
          "show": true,
          "logBase": 1,
          "min": "0",
          "max": "1"
        },
        {
          "show": false
        }
      ],
      "xaxis": {
        "show": true
      },
      "dashLength": 10,
      "linewidth": 1,
      "pointradius": 2,
      "bars": false,
      "lines": true,
      "fill": 1,
      "fillGradient": 0,
      "aliasColors": {},
      "seriesOverrides": [],
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "description": "Confidence levels of model predictions"
    }
  ],
  "refresh": "10s",
  "schemaVersion": 22,
  "version": 1,
  "links": []
}

